data <- data %>%
dplyr::select(-c(delect$variables))
}
} else {
data <- data_m[
stats::complete.cases(data_m), ]
} # end autocorrelation loop
partition_indexes <- caret::createDataPartition(data$plot,
times = 1,
p = p,
list = FALSE)
trainingDat <- data[partition_indexes, ]
testingDat <- data[-partition_indexes, ]
View(testingDat)
data$plot
partition_indexes <- caret::createDataPartition(data$plot,
times = 1,
p = 0.8,
list = FALSE)
partition_indexes <- caret::createDataPartition(data$plot,
times = 1,
p = 0.5,
list = FALSE)
partition_indexes <- caret::createDataPartition(data$datetime,
times = 1,
p = p,
list = FALSE)
data
View(data)
View(data_o)
trainingDat <- data[partition_indexes, ]
testingDat <- data[-partition_indexes, ]
# Loop for SpaceTimeFolds --------------------------------------- DoFolds --- #
for (fo in 1:length(dofolds)){
f <- dofolds[fo]
if(!is.null(seed)){set.seed(seed)}
if (f == "LLO"){
fold <- CAST::CreateSpacetimeFolds(
trainingDat,
spacevar = "plot"
)
# talk to the user
message(
paste0(
"Run with spatial folds for cross validation.  Fold-Nr.: ",
which(f == dofolds), "/", length(dofolds)
)
)
} # end LLO
if (f == "LTO"){
fold <- CAST::CreateSpacetimeFolds(
trainingDat,
timevar = "datetime"
)
# talk to the user
message(
paste0(
"Run with temporal folds for cross validation.  Fold-Nr.: ",
which(f == dofolds), "/", length(dofolds)
)
)
} # end LTO
if (f == "LLTO"){
fold <- CAST::CreateSpacetimeFolds(
trainingDat,
timevar = "datetime",
spacevar = "plot"
)
# talk to the user
message(
paste0(
"Run with spatio-temporal folds for cross validation.  Fold-Nr.: ",
which(f == dofolds), "/", length(dofolds)
)
)
} # end LLTO
ctrl <- caret::trainControl(
method = "cv",
index = fold$index,
savePredictions = TRUE
)
if (autocorrelation == TRUE){
preds <- trainingDat[, utils::head(predrows,
-length(delect$variables)
)
]
} else {
preds <- trainingDat[, predrows]
} # end autocorrelation-loop
# set response
resps <- trainingDat[ ,s]
# talk to the user
message(
paste0(
"Calculate models for sensor: ",
sensor_names[which(s == climresp)])
)
# create date
date <- ifelse(
m < 10,
paste0(y, "0", m),
paste0(y, m)
)
# save the training and testing data for further evaluation
utils::write.csv(
trainingDat,
file = file.path(
envrmt$path_tfinal,
paste0(
date,
"_",
mnote,
"_",
sensor_names[which(s == climresp)],
"_trainingDat.csv"
)
)
)
utils::write.csv(
testingDat,
file = file.path(
envrmt$path_tfinal,
paste0(
date,
"_",
mnote,
"_",
sensor_names[which(s == climresp)],
"_testingDat.csv")
)
)
# Loop for Classifiers --------------------------------------- Classifier --- #
# start classifier loop
for (i in 1:length(classifier)) try ({
method <- classifier[i]
tuneLength = 2
tuneGrid <- NULL
# adjust settings for different model types
if (method == "gbm"){
tuneLength <- 10
ctrl <- caret::trainControl(
method = "repeatedcv",
number = 10,
repeats = 10,
savePredictions = TRUE)
modclass <-"gbm"
# talk to the user
message(paste0("Next model: Stochastic Gradient Boosting.  ", i, "/", length(classifier)))
}
if (method == "lm"){
tuneLength <- 10
modclass <- "lim"
# talk to the user
message(paste0("Next model: Linear Regression.  ", i, "/", length(classifier)))
}
if (method == "rf"){
tuneLength <- 1
tuneGrid <- expand.grid(mtry = 2)
modclass <- "raf"
# talk to the user
message(paste0("Next model: Random Forest.  ", i, "/", length(classifier)))
}
if (method == "pls"){
#              preds <- data.frame(scale(preds))
tuneLength <- 10
modclass <- "pls"
# talk to the user
message(paste0("Next model: Partial-Least-Squares.  ", i, "/", length(classifier)))
}
if (method == "nnet"){
tuneLength <- 1
tuneGrid <- expand.grid(size = seq(2,ncol(preds),2),
decay = seq(0,0.1,0.025)
)
modclass <- "nnt"
# talk to the user
message(paste0("Next model: Neural Networks.  ", i, "/", length(classifier)))
}
# talk to the user
message("Computing model...")
# calculate model
ffsmodel <- CAST::ffs(
predictors = preds,
response = resps,
metric = "RMSE",
withinSE = FALSE,
method = method,
importance = TRUE,
tuneLength = tuneLength,
tuneGrid = tuneGrid,
trControl = ctrl,
linout = TRUE,
verbose = FALSE,
trace = FALSE
)
# save all models
saveRDS(
ffsmodel,
file.path(
envrmt$path_models,
paste0(
mnote,
"_",
sensor_names[which(s == climresp)],
"_",
date,
"_",
f,
"_",
modclass,
"_ffs_model.rds")))
# Evaluation Data Frame ----------------------------------------------------- #
# create data frame for model evaluation
if (method == "gbm"){
accuracy = min(ffsmodel$results$RMSE)
} else {
accuracy <- min(ffsmodel$selectedvars_perf)
}
df <- data.frame(
year_month = date,
classifier = modclass,
accuracy = accuracy,
Nrmse = accuracy / (max(resps) - min(resps)),
Rsqrd = ffsmodel$results[1,3],
sensor = sensor_names[which(s == climresp)],
modeltype = f,
note = mnote)
#add the vars in list
if (method == "gbm"){
df$variables[1] = list(c(colnames(ffsmodel$ptype)))
} else {
df$variables[1] = list(c(ffsmodel$selectedvars))
}
df_total <- rbind(df_total, df)
#           remove(ffsmodel)
#           gc()
}) # end classifier loop [i]
} # end fold loop [f]
#talk to the user
message("Done! Saving evaluation data frame.")
# save total loop analytics for eval
saveRDS(df_total, file.path(envrmt$path_statistics, paste0(mnote, "_mod_eval_df.rds")));
# stop paralellization, if it was activated
if (doParallel == TRUE){
#talk to the user
message("Ending parallelization.")
parallel::stopCluster(cl)
}
# Read testing data
test <- read.csv(
file.path(
envrmt$path_tfinal,
paste0(
dates[i],
"_",
mnote,
"_",
mod_df[i, ]$sensor,
"_testingDat.csv"
)
)
)
library(climodr)
# setting up the environment for climodr
envrmt <- envi.create(tempdir(),
memfrac = 0.8)
# load in all the climodr example data for this vignette
clim.sample(envrmt = envrmt)
# remove everything in the global environment except of our environment path list
rm(list = setdiff(ls(), "envrmt"))
prep.csv(envrmt = envrmt,
method = "proc",
save_output = TRUE)
#check the created csv files
csv_files <- grep("_no_NAs.csv$",
list.files(envrmt$path_tworkflow),
value=TRUE)
csv_files
csv_data <- proc.csv(envrmt = envrmt,
method = "monthly",
rbind = TRUE,
save_output = TRUE)
head(csv_data)
csv_spat <- spat.csv(envrmt = envrmt,
method = "monthly",
des_file = "plot_description.csv",
save_output = TRUE)
head(csv_spat)
crop.all(envrmt = envrmt,
method = "MB_Timeseries",
overwrite = TRUE)
calc.indices(envrmt = envrmt,
vi = "all",
bands = c("blue", "green", "red",
"nir", "nirb",
"re1", "re2", "re3",
"swir1", "swir2"),
overwrite = TRUE)
csv_fin <- fin.csv(envrmt = envrmt,
method = "monthly",
save_output = TRUE)
head(csv_fin)
autocorr(
envrmt = envrmt,
method = "monthly",
max_pvalue = 0.05,
resp = 5,
pred = c(8:23),
plot.corrplot = FALSE,
corrplot = "coef"
)
eval_df <- calc.model(
envrmt = envrmt,
method = "monthly",
timespan = c(2017),
climresp = c(5),
classifier = c(
"raf",
"lim",
"pls"),
seed = 707,
p = 0.8,
folds = "LLO",
mnote = "vignette",
predrows = c(8:23),
tc_method = "cv",
metric = "RMSE",
autocorrelation = TRUE,
doParallel = FALSE)
eval_df
method = "monthly"
metric = "accuracy"
mnote = "vignette"
AOA = TRUE
# create list for results and later function output
results <- list()
val <- data.frame(model_name = character(),
RMSE = integer(),
SD = integer())
# create a list with all raster images
tiff_list <- list.files(
path = envrmt$path_rfinal,
pattern = ".tif",
recursive = TRUE
)
# read dgm
dgm <- terra::rast(
file.path(
envrmt$path_rfinal,
grep(
pattern = "_dgm_",
tiff_list,
value = TRUE)
)
)
# read eval_df
eval_df <- readRDS(
file.path(
envrmt$path_statistics,
paste0(
mnote,
"_mod_eval_df.rds"
)
)
)
# filter for best models
if(!metric %in%  c("accuracy", "Nrmse", "Rsqrd")){
stop("Your 'metric' argument has to consist of either 'accuracy', 'Nrmse' or 'Rsqrd'.\n Stopped execution, no model could be choosen with missing metric.")
}
expr <- c(expression(mod_date$accuracy == max(mod_date$accuracy)),
expression(mod_date$Nrmse == min(mod_date$Nrmse)),
expression(mod_date$Rsqrd == min(mod_date$Rsqrd)))[which(
metric == c("accuracy", "Nrmse", "Rsqrd")
)]
dates <- unique(eval_df[, 1])
i = 1
mod_date <- eval_df[which(eval_df[, 1] == dates[i]), ]
ifelse(
i == 1,
mod_df <- mod_date[
which(eval(expr)), ],
mod_df[i, ] <- mod_date[
which(eval(expr)), ]
)
# read fitting raster
raster <- terra::rast(
file.path(
envrmt$path_rfinal,
grep(
pattern = dates[i],
tiff_list,
value = TRUE
)
)
)
terra::add(raster) <- dgm
modname <- paste0(
mnote,
"_",
mod_df[i, ]$sensor,
"_",
dates[i],
"_",
mod_df[i, ]$modeltype,
"_",
mod_df[i, ]$classifier
)
mod <- readRDS(
file.path(
envrmt$path_models,
paste0(modname,
"_ffs_model.rds")
)
)
# Read testing data
test <- read.csv(
file.path(
envrmt$path_tfinal,
paste0(
dates[i],
"_",
mnote,
"_",
mod_df[i, ]$sensor,
"_testingDat.csv"
)
)
)
View(test)
test$X <- NULL
View(test)
View(test)
View(test)
View(test)
terra::crs(raster)
test <- terra::vect(test,
geom = c("x", "y"),
crs = terra::crs(raster))
test
ext <- terra::extract(test,
raster)
ext <- terra::extract(raster,
test)
ext
View(ext)
message(
paste0(
"Making ",
mod_df[i, ]$sensor,
" ",
mod_df[i, ]$classifier,
"-prediction for ",
dates[i],
"."
)
)
pred <- terra::predict(
raster,
mod,
na.rm = TRUE
)
names(pred) <- modname
terra::writeRaster(
pred,
file.path(
envrmt$path_predictions,
paste0(
modname,
"_prediction.tif"
)
),
overwrite = TRUE
)
# calculate validation
ext <- terra::extract(pred,
test)
View(ext)
View(test)
test[[]]
test[
]
terra::values(test)
terra::values(test)[mod_df[i, ]$sensor]
# now, fill up the validation metrics
ext$res <- terra::values(test)[mod_df[i, ]$sensor]
View(ext)
# calculate validation
ext <- terra::extract(pred,
test)
# now, fill up the validation metrics
ext$sensor <- terra::values(test)[mod_df[i, ]$sensor]
View(ext)
names(ext) <- c("Pred", "Obsv")
View(ext)
# calculate validation
ext <- terra::extract(pred,
test)
# now, fill up the validation metrics
ext$sensor <- terra::values(test)[mod_df[i, ]$sensor]
names(ext) <- c("ID", "Pred", "Obsv")
View(ext)
terra::values(test)[mod_df[i, ]$sensor][1]
terra::values(test)[mod_df[i, ]$sensor][1,]
terra::values(test)[mod_df[i, ]$sensor][,1]
# calculate validation
ext <- terra::extract(pred,
test)
# now, fill up the validation metrics
ext$sensor <- terra::values(test)[mod_df[i, ]$sensor][,1]
names(ext) <- c("ID", "Pred", "Obsv")
View(ext)
View(val)
