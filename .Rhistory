df <- data.frame(data[,1:(l-1)],
lat = sp::coordinates(data)[,2],
lon = sp::coordinates(data)[,1]
)
View(data)
View(df)
df <- data.frame(data)
View(df)
df$optional <- NULL
df <- df[n[1:(l-1)], "lat", "lon", n[l]]
n[l]
df <- df[, n[1:(l-1)], "lat", "lon", n[l]]
df <- df[, c(n[1:(l-1)], "lat", "lon", n[l])]
View(df)
# Prepare CSV-Data
climodr::prep.csv(method = "proc", safe_output = TRUE)
devtools::load_all()
### Initiate Climodr ###
climodr::envi.create("E:/climodr/showcase")
# Prepare CSV-Data
climodr::prep.csv(method = "proc", safe_output = TRUE)
# Check the created csv files
csv_files <- grep("_no_NAs.csv$", list.files(envrmt$path_tworkflow), value=TRUE)
csv_files
# Process CSV-Data
csv_data <- climodr::proc.csv(method = "all",
rbind = TRUE,
safe_output = TRUE)
# Check again
head(csv_data)
# Create spatial CSV-Data
csv_spat <- climodr::spat.csv(method = "monthly",
des_file = "plot_description.csv",
safe_output = TRUE)
data <- read.csv(file.path(envrmt$path_tworkflow, "all_monthly_means.csv"));
cn_data <- colnames(data)
names_of_stations <- as.vector(unlist(unique(data[1])))
number_of_stations <- length(names_of_stations)
for (i in 1:number_of_csvs){
x <- read.csv(file.path(envrmt$path_tworkflow, paste0(csv_paths[i])))
x <- data.frame(x)
if (i == 1) {
data <- x
} else {
data <- rbind(data, x)
}
des <- read.csv(file.path(envrmt$path_dep, des_file));
data$lat <- "";
data$lon <- "";
data$elevation <- "";
### Initiate Climodr ###
climodr::envi.create("E:/climodr/showcase")
des <- read.csv(file.path(envrmt$path_dep, des_file));
des_file = "plot_description.csv"
des <- read.csv(file.path(envrmt$path_dep, des_file));
data$lat <- "";
data$lon <- "";
data$elevation <- "";
for (i in 1:number_of_stations){
data$lat[which(data$plot == names_of_stations[i])] <- des$lat[which(grepl(names_of_stations[i], des$plot))]
data$lon[which(data$plot == names_of_stations[i])] <- des$lon[which(grepl(names_of_stations[i], des$plot))]
data$elevation[which(data$plot == names_of_stations[i])] <- des$elevation[which(grepl(names_of_stations[i], des$plot))]
};
data$day <- 1
data$datetime <-as.Date(with(data,paste(year,month,day,sep="-")),"%y-%m-%d");
data <- data[,c(cn_data[1],
"datetime",
cn_data[2:3],
"day",
cn_data[4:length(cn_data)],
"lat",
"lon",
"elevation"
)];
mms <- 6:(2 + length(cn_data));
for (i in mms){
data[i] <- round(data[i], digits = 3)
};
names(data)  <- c(names(data[1:5]),
gsub("monthly_mean_", "", names(data[mms])),
names(data[(3 + length(cn_data)):length(names(data))])
);
if (is.null(crs)){
crs <- terra::crs(terra::rast(file.path(envrmt$path_dep, "res_area.tif")))
}
if (is.null(crs)){
crs <- terra::crs(terra::rast(file.path(envrmt$path_dep, "res_area.tif")))
}
crs = NULL
if (is.null(crs)){
crs <- terra::crs(terra::rast(file.path(envrmt$path_dep, "res_area.tif")))
}
sp::coordinates(data) <- ~ lon + lat
View(data)
sp::coordinates(data) <- ~ "lon" + "lat"
is.numeric(data$lat)
data$lat <- as.numeric(data$lat)
data$lon <- as.numeric(data$lon)
is.numeric(data$lat)
sp::coordinates(data) <- ~ lon + lat
sp::proj4string(data) <- sp::CRS("+proj=longlat +datum=WGS84")
data <- sp::spTransform(data, crs)
n <- names(data)
l <- length(n)
df <- data.frame(data)
df$optional <- NULL
df <- df[, c(n[1:(l-1)],
"lat",
"lon",
n[l]
)
]
data <- data.frame(data)
data$optional <- NULL
data <- data[, c(n[1:(l-1)],
"lat",
"lon",
n[l]
)
]
devtools::load_all()
### Initiate Climodr ###
climodr::envi.create("E:/climodr/showcase")
# Create spatial CSV-Data
csv_spat <- climodr::spat.csv(method = "monthly",
des_file = "plot_description.csv",
safe_output = TRUE)
# Check again
head(csv_spat)
### Initiate Climodr ###
climodr::envi.create("E:/climodr/showcase")
data <- read.csv(file.path(envrmt$path_tworkflow, "spat_monthly_means.csv"));
cn_data <- colnames(data)
names_of_stations <- as.vector(unlist(unique(data[1])))
number_of_stations <- length(names_of_stations)
tiff_list <- list();
all_files_in_distribution <- list.files(path = file.path(envrmt$path_wraster), recursive = T); #reads all data in Workflow Raster Folder
tiff_paths <- grep(".tif$", all_files_in_distribution, value=TRUE); # Select tiff-files
number_of_tiffs <- length(tiff_paths);
for (i in number_of_tiffs){
tiff_list[[i]] <- terra::rast(file.path(envrmt$path_wraster, tiff_paths[[i]]))
if (i == 1){
tiff_stack <- tiff_list[[i]]
} else {
terra::add(tiff_stack) <- tiff_list[[i]]
}
for (i in 1:number_of_tiffs){
tiff_list[[i]] <- terra::rast(file.path(envrmt$path_wraster, tiff_paths[[i]]))
if (i == 1){
tiff_stack <- tiff_list[[i]]
} else {
terra::add(tiff_stack) <- tiff_list[[i]]
}
extr <- terra::extract(tiff_stack, data)
extr <- terra::extract(tiff_stack, data.frame(x = data$lon,
y = data$lat
)
View(extr)
extr <- terra::extract(tiff_stack,
data.frame(x = data$lon,
y = data$lat),
ID = data$plot
)
data$ID <- seq(1:length(data[,1]))
View(data)
data <- merge(data, extr, by = "ID")
View(data)
write.csv(data, file.path(envrmt$path_tfinal, "final_clim_monthly.csv"), row.names = FALSE);
data_o <- read.csv(file.path(envrmt$path_tfinal, "final_monthly.csv"));
df_total <- data.frame();
# Modelling
climodr::calc.model(timespan = 18,
response = c(6,9,12,13),
classifier = c("rf", "pls","nnet" ,"lm"),
seed = 707,
p = 0.8,
fold = "LTO",
predrows = c(16:57),
k = 12,
tc_method = "cv",
metric = "RMSE")
install.packages("DescTools")
library(DescTools)
# Modelling
climodr::calc.model(timespan = 18,
response = c(6,9,12,13),
classifier = c("rf", "pls","nnet" ,"lm"),
seed = 707,
p = 0.8,
fold = "LTO",
predrows = c(16:57),
k = 12,
tc_method = "cv",
metric = "RMSE")
# Modelling
climodr::calc.model(timespan = 18,
response = c(6,9,12,13),
classifier = c("rf", "pls","nnet" ,"lm"),
seed = 707,
p = 0.8,
fold = "LTO",
predrows = c(16:57),
k = 12,
tc_method = "cv",
metric = "RMSE")
devtools::load_all()
# Modelling
climodr::calc.model(timespan = 18,
response = c(6,9,12,13),
classifier = c("rf", "pls","nnet" ,"lm"),
seed = 707,
p = 0.8,
fold = "LTO",
predrows = c(16:57),
k = 12,
tc_method = "cv",
metric = "RMSE")
View(data)
# Finalize CSV-Data
csv_fin <- climodr::fin.csv(method = "monthly",
safe_output = TRUE)
### Initiate Climodr ###
climodr::envi.create("E:/climodr/showcase")
# Finalize CSV-Data
csv_fin <- climodr::fin.csv(method = "monthly",
safe_output = TRUE)
# Modelling
climodr::calc.model(timespan = 18,
response = c(6,9,12,13),
classifier = c("rf", "pls","nnet" ,"lm"),
seed = 707,
p = 0.8,
fold = "LTO",
predrows = c(16:56),
k = 12,
tc_method = "cv",
metric = "RMSE")
data_o <- read.csv(file.path(envrmt$path_tfinal, "final_monthly.csv"));
df_total <- data.frame();
library(DescTools)
y=18
data_y <- data_o[data_o$year %like% y, ]
data <- data_y[complete.cases(data_y), ]
time <- y
print(time)
s=6
partition_indexes <- caret::createDataPartition(data$plotID,
times = 1,
p = p,
list = FALSE)
devtools::load_all()
# Modelling
climodr::calc.model(timespan = 18,
response = c(6,9,12,13),
classifier = c("rf", "pls","nnet" ,"lm"),
seed = 707,
p = 0.8,
fold = "LTO",
predrows = c(16:56),
k = 12,
tc_method = "cv",
metric = "RMSE")
# Modelling
climodr::calc.model(timespan = 18,
response = 6,
classifier = "rf",
seed = 707,
p = 0.8,
fold = "LTO",
predrows = c(16:56),
k = 12,
tc_method = "cv",
metric = "RMSE")
data_o <- read.csv(file.path(envrmt$path_tfinal, "final_monthly.csv"));
df_total <- data.frame();
data_y <- data_o[data_o$year %like% y, ]
data <- data_y[complete.cases(data_y), ]
time <- y
data_o <- read.csv(file.path(envrmt$path_tfinal, "final_monthly.csv"));
View(data_o)
# Finalize CSV-Data
csv_fin <- climodr::fin.csv(method = "monthly",
safe_output = TRUE)
data_o <- read.csv(file.path(envrmt$path_tfinal, "final_monthly.csv"));
df_total <- data.frame();
data_y <- data_o[data_o$year %like% y, ]
data <- data_y[complete.cases(data_y), ]
time <- y
print(time)
seed = 707
set.seed(seed)
partition_indexes <- caret::createDataPartition(data$plot,
times = 1,
p = p,
list = FALSE)
p = 0.8
partition_indexes <- caret::createDataPartition(data$plot,
times = 1,
p = p,
list = FALSE)
trainingDat <- data[partition_indexes, ]
testingDat <- data[-partition_indexes, ]
k = 12
folds <- CAST::CreateSpacetimeFolds(trainingDat, timevar = "datetime", k = k) #set k to the number of unique spatial or temporal units. (k = 12)
View(folds)
ctrl <- caret::trainControl(method = "cv",
index = folds$index,
savePredictions=TRUE
)
predrows = c(16:56)
predictors <- trainingDat[ ,predrows]
response <- trainingDat[ ,s]
print(colnames(trainingDat[s]))
sensor <- colnames(trainingDat[s])
classifier = c("rf", "pls","nnet" ,"lm")
i=1
tc_method = "cv",
tc_method = "cv"
metric = "RMSE"
ctrl <- caret::trainControl(
method = tc_method,
index = folds$index,
indexOut = folds$indexOut
)
method = classifier[i]
print(method)
tuneLength <- 1
tuneGrid <- expand.grid(mtry = 2)
ifnnet <- FALSE
ffsmodel <- CAST::ffs(predictors,
response,
metric = metric,
withinSE = TRUE,
method = method,
importance =TRUE,
tuneLength = tuneLength,
tuneGrid = tuneGrid,
trControl = ctrl,
trace = ifnnet,
linout = TRUE,
verbose = ifnnet)
warnings()
View(envrmt)
ffsmodel <- CAST::ffs(predictors,
response,
metric = metric,
withinSE = TRUE,
method = method,
importance =TRUE,
tuneLength = tuneLength,
#tuneGrid = tuneGrid,
trControl = ctrl,
trace = ifnnet,
linout = TRUE,
verbose = ifnnet)
warnings()
model <- CAST::ffs(predictors,
response,
metric = metric,
withinSE = TRUE,
method = method,
importance =TRUE,
tuneLength = tuneLength,
tuneGrid = tuneGrid,
trControl = ctrl,
trace = ifnnet,
linout = TRUE,
verbose = ifnnet)
warnings()
ffsmodel <- CAST::ffs(predictors,
response,
metric = metric,
withinSE = TRUE,
method = method,
importance =TRUE,
tuneLength = tuneLength,
tuneGrid = tuneGrid,
trControl = ctrl,
trace = ifnnet,
linout = TRUE,
verbose = ifnnet)
View(predictors)
predictors$elevation.y <- NULL
ffsmodel <- CAST::ffs(predictors,
response,
metric = metric,
withinSE = TRUE,
method = method,
importance =TRUE,
tuneLength = tuneLength,
tuneGrid = tuneGrid,
trControl = ctrl,
trace = ifnnet,
linout = TRUE,
verbose = ifnnet)
# Type: script
# Name: template-script.R
# Author:
# Description: set necessary variables and calls setup
# Dependencies: geoAI_setup.R
# Output: list of pathes
# Copyright: 2021, GPL (>= 3)
#------------------------------------------------------------------------------
# 0 - specific setup
#-----------------------------
require(envimaR)
# MANDANTORY: defining the root folder DO NOT change this line
rootDIR = "C:/Users/Alexander/Documents/Uni/WiSe22/GeoAI"
# Type: script
# Name: template-script.R
# Author:
# Description: set necessary variables and calls setup
# Dependencies: geoAI_setup.R
# Output: list of pathes
# Copyright: 2021, GPL (>= 3)
#------------------------------------------------------------------------------
# 0 - specific setup
#-----------------------------
require(envimaR)
# MANDANTORY: defining the root folder DO NOT change this line
rootDIR = "C:/Users/Alexander/Documents/Uni/WiSe22/GeoAI"
#-- Further customization of the setup by the user this section
#-- can be freely customized only the definition of additional packages
#-- and directory paths MUST be done using the two variables
#-- appendpackagesToLoad and appendProjectDirList
#-- feel free to remove this lines if you do not need them
# define  additional packages uncomment if necessary
appendpackagesToLoad <- c("png", "gdalUtils", "tensorflow", "osmdata",
"greenbrown", "rsample", "tfdatasets",
"purrr", "stars", "magick")
# define additional subfolders uncomment if necessary
appendProjectDirList <- c("data/modelling/",
"data/modelling/model_training_data/",
"data/modelling/model_training_data/dop/",
"data/modelling/model_training_data/bui/",
"data/modelling/models/",
"data/modelling/prediction/",
"data/modelling/validation/",
"data/modelling/model_testing_data/",
"data/modelling/model_testing_data/dop/",
"data/modelling/model_testing_data/bui/",
"src/functions/")
# MANDANTORY: calling the setup script also DO NOT change this line
source(file.path(envimaR::alternativeEnvi(root_folder = rootDIR),"src/geoAI_setup.R"),echo = TRUE)
# list the files again
files <- data.frame(
img = list.files(
file.path(envrmt$path_model_training_data_dop),
full.names = TRUE,
pattern = "*.png"
),
mask = list.files(
file.path(envrmt$path_model_training_data_bui),
full.names = TRUE,
pattern = "*.png"
)
# split randomly into training and validation (not testing!!) data sets
set.seed(7)
data <- initial_split(files, prop = 0.8)
source(file.path(envrmt$path_functions, "U4_EX_2_Fun.R"))
# one more parameter
batch_size = 8
model_input_shape = c(128, 128)
# prepare data for training
training_dataset <-
prepare_ds(
training(data),
train = TRUE,
predict = FALSE,
model_input_shape = model_input_shape,
batch_size = batch_size
)
validation_dataset <-
prepare_ds(
testing(data),
train = FALSE,
predict = FALSE,
model_input_shape = model_input_shape,
batch_size = batch_size
)
# we first get a all our training data
it <- as_iterator(training_dataset)
it <- iterate(it)
# we convert our data to an array and also subset our iterator e.g.
# with the 4th batch ([[4]]) of the images ([[1]])
im <-as.array(it[[4]][[1]])
# then we subset just take the first image out of our batch
im <- im[1,,,]
# and plot it
plot(as.raster(im))
# and for the according mask it is almost the same
ma <-as.array(it[[4]][[2]])
ma <- ma[1,,,]
plot(as.raster(ma))
#model
unet_model <- get_unet_128()
# compile the model
unet_model %>% compile(
optimizer = optimizer_adam(learning_rate = 0.0001),
loss = "binary_crossentropy",
metrics = "accuracy"
)
# train the model
hist <- unet_model %>% fit(
training_dataset,
validation_data = validation_dataset,
epochs = 10,
verbose = 1
)
# save the model
unet_model %>% save_model_hdf5(file.path(envrmt$path_models, "unet_buildings.hdf5"))
plot(hist)
